{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expectation maximization algorithm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "glDYdhsRfp_t"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O3xLkA8fz6L"
      },
      "source": [
        "# EM algorithm \n",
        "# random initial means\n",
        "def rand_gaussian_mean(data, k):\n",
        "    dim = len(data[0,:])\n",
        "    means = np.empty([k,dim])\n",
        "    \n",
        "    for i in range(dim):\n",
        "        # Picking k random numbers between min and max of each column\n",
        "        means[:,i] = np.random.uniform(min(data[:,i]), max(data[:,i]), k)\n",
        "        \n",
        "    return means\n",
        "\n",
        "#random initial covariance\n",
        "def rand_gaussian_cov(data,k):\n",
        "    dim = len(data[0,:])\n",
        "    initial_cov = np.empty([k,dim,dim])\n",
        "    \n",
        "    # Choosing a random initial diagonal covariance matrix!\n",
        "    for i in range(k):\n",
        "        initial_cov[i,:,:] = np.diag(np.random.randint(1,3, dim))\n",
        "        \n",
        "    return initial_cov\n",
        "\n",
        "\n",
        "# random initial weights\n",
        "def mixing_coefficients(k):\n",
        "    x = np.random.randint(1,2,k)\n",
        "    x = x/sum(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "# gaussian pdf\n",
        "def multi_gaussian(x,m,c):\n",
        "    return multivariate_normal.pdf(x,mean = m, cov = c)\n",
        "\n",
        "\n",
        "# vector tanspose multiplication\n",
        "def vec_multiplication(x):\n",
        "    dim = len(x)\n",
        "    mat = np.empty([dim,dim])\n",
        "    for i in range(dim):\n",
        "        mat[i,:] = x[i] * x\n",
        "    return mat\n",
        "\n",
        "\n",
        "# data is the data file, k is the number of required clusters.\n",
        "def EM(file,k):\n",
        "    \n",
        "    \n",
        "    data =  file.to_numpy()\n",
        "    # Correcting shape for 1-dim arrays:\n",
        "    if data.shape == (len(data),):\n",
        "      data = np.reshape(data, (len(data),1))\n",
        "    else:\n",
        "      pass\n",
        "      \n",
        "    # No. of observations\n",
        "    observations = len(data)\n",
        "    \n",
        "    # Dimension of data\n",
        "    dim = len(data.T)\n",
        "   \n",
        "    # initial mean points\n",
        "    initial_means = rand_gaussian_mean(data,k)\n",
        "    #print(\"initial means:\", initial_means, \"\\n\")\n",
        "   \n",
        "    # initial covariances( I am taking them to be diagonal!)\n",
        "    initial_cov = rand_gaussian_cov(data,k)\n",
        "    #print(\"initial cov:\" , initial_cov, \"\\n\")\n",
        "    \n",
        "    # new mean\n",
        "    means = initial_means\n",
        "    \n",
        "    # probabilities with means\n",
        "    responsibilities = np.empty([observations,k])\n",
        "    cov = initial_cov\n",
        "    effective_number_of_points = np.empty(k)\n",
        "    \n",
        "    # initial mixture weight\n",
        "    ini_weight = mixing_coefficients(k)\n",
        "    weights = ini_weight\n",
        "    #print(\" Initial mixing weights:\", weights, \"\\n\")\n",
        "    \n",
        "    old_means = np.zeros([k,dim])\n",
        "\n",
        "    counter = 0\n",
        "    \n",
        "    while np.not_equal(old_means,means).any():\n",
        "        \n",
        "    #for n in range(500):\n",
        "      counter = counter +1\n",
        "        \n",
        "        # Finding responsibilities! - This is the Expectation step.\n",
        "      for i in range(observations):\n",
        "        denominator = 0\n",
        "        for l in range(k):\n",
        "          denominator = denominator + weights[l] * multi_gaussian(data[i,:],means[l,:],cov[l,:,:])\n",
        "        for j in range(k):\n",
        "          responsibilities[i,j] = ( weights[j] * multi_gaussian(data[i,:],means[j,:],cov[j,:,:]))/denominator\n",
        "                \n",
        "        # Finding effective number of points:       \n",
        "      for i in range(k):\n",
        "         effective_number_of_points[i] = np.sum(responsibilities[:,i])\n",
        "            \n",
        "            \n",
        "      old_means = np.copy(means)\n",
        "      \n",
        "        \n",
        "        #Finding new parameters. - The Maximization step!\n",
        "        \n",
        "        # finding new mean:\n",
        "      for i in range(k):\n",
        "        mu = np.zeros(dim)\n",
        "        for j in range(observations):\n",
        "           mu = mu + (responsibilities[j,i] * data[j,:])\n",
        "           means[i,:] = mu/(effective_number_of_points[i])\n",
        "            \n",
        "            \n",
        "        # finding new covariance matrix:\n",
        "      for i in range(k):\n",
        "        new_cov = np.zeros([dim,dim])\n",
        "        for j in range(observations):\n",
        "          new_cov = new_cov + responsibilities[j,i]* vec_multiplication(data[j,:]-means[i,:])\n",
        "          cov[i,:,:] = new_cov/(effective_number_of_points[i])\n",
        "            \n",
        "            \n",
        "        # find new weights:\n",
        "      for i in range(k):\n",
        "        weights[i] = effective_number_of_points[i]/observations\n",
        "\n",
        "    # Identifying which cluster the data point belongs!\n",
        "    cluster = np.empty(observations)\n",
        "    for i in range(observations):\n",
        "      cluster[i] = np.argmax(responsibilities[i,:])\n",
        "\n",
        "    # Selecting random colour parameters for plotting. \n",
        "    colour = np.empty([k,3])\n",
        "    for i in range(k):\n",
        "        colour[i,:] = np.random.rand(3) \n",
        "\n",
        "    if k == 2:\n",
        "        colour = ['g','r']\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    # Plotting graph for datas with two dimension. \n",
        "    if dim == 2:\n",
        "        plt.figure()\n",
        "        plt.xlabel(file.columns[0])\n",
        "        plt.ylabel(file.columns[1])\n",
        "        for i in range(observations):\n",
        "            plt.scatter(data[i,1],data[i,0], color = colour[int(cluster[i])])\n",
        "            #plt.xaxis = (file.columns[0])\n",
        "            #plt.yaxis = (file.columns[1])\n",
        "        for i in range(k):\n",
        "            plt.scatter(means[i,0],means[i,1], marker = \"+\" , color = colour[i])\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    print(\"Iterations:\", counter,\"\\n\")\n",
        "    #print(\"old means:\", old_means,\"\\n\")\n",
        "    print(\"Controid/Means:\", means,\"\\n\")\n",
        "    #print(\"While loop condition\", np.not_equal(old_means, means).any(), \"\\n\")\n",
        "    return \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}